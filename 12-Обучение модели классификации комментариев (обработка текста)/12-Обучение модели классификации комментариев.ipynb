{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-и-изучение-данных\" data-toc-modified-id=\"Загрузка-и-изучение-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Загрузка и изучение данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Общая-информация-о-файле\" data-toc-modified-id=\"Общая-информация-о-файле-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Общая информация о файле</a></span></li><li><span><a href=\"#Предобработка-данных\" data-toc-modified-id=\"Предобработка-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Предобработка данных</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-признаков-к-обучению-моделей\" data-toc-modified-id=\"Подготовка-признаков-к-обучению-моделей-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Подготовка признаков к обучению моделей</a></span></li><li><span><a href=\"#CountVectorizer\" data-toc-modified-id=\"CountVectorizer-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>CountVectorizer</a></span><ul class=\"toc-item\"><li><span><a href=\"#Линейная-регрессия\" data-toc-modified-id=\"Линейная-регрессия-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Линейная регрессия</a></span></li><li><span><a href=\"#CatBoostClassifier\" data-toc-modified-id=\"CatBoostClassifier-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>CatBoostClassifier</a></span></li><li><span><a href=\"#LGBMClassifier\" data-toc-modified-id=\"LGBMClassifier-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>LGBMClassifier</a></span></li><li><span><a href=\"#SGDClassifier\" data-toc-modified-id=\"SGDClassifier-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>SGDClassifier</a></span></li><li><span><a href=\"#XGBClassifier\" data-toc-modified-id=\"XGBClassifier-2.2.5\"><span class=\"toc-item-num\">2.2.5&nbsp;&nbsp;</span>XGBClassifier</a></span></li></ul></li><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>TF-IDF</a></span><ul class=\"toc-item\"><li><span><a href=\"#Линейная-регрессия\" data-toc-modified-id=\"Линейная-регрессия-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Линейная регрессия</a></span></li><li><span><a href=\"#CatBoostClassifier\" data-toc-modified-id=\"CatBoostClassifier-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>CatBoostClassifier</a></span></li><li><span><a href=\"#LGBMClassifier\" data-toc-modified-id=\"LGBMClassifier-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>LGBMClassifier</a></span></li><li><span><a href=\"#SGDClassifier\" data-toc-modified-id=\"SGDClassifier-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>SGDClassifier</a></span></li><li><span><a href=\"#XGBClassifier\" data-toc-modified-id=\"XGBClassifier-2.3.5\"><span class=\"toc-item-num\">2.3.5&nbsp;&nbsp;</span>XGBClassifier</a></span></li></ul></li></ul></li><li><span><a href=\"#Проверка-моделей-на-тестовой-выборке\" data-toc-modified-id=\"Проверка-моделей-на-тестовой-выборке-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Проверка моделей на тестовой выборке</a></span><ul class=\"toc-item\"><li><span><a href=\"#Тестированиние-моделей-построенных-с-помощью-&quot;мешка-слов&quot;\" data-toc-modified-id=\"Тестированиние-моделей-построенных-с-помощью-&quot;мешка-слов&quot;-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Тестированиние моделей построенных с помощью \"мешка слов\"</a></span></li><li><span><a href=\"#Тестирование-моделей-созданных-с-помощью-TF-IDF\" data-toc-modified-id=\"Тестирование-моделей-созданных-с-помощью-TF-IDF-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Тестирование моделей созданных с помощью TF-IDF</a></span></li></ul></li><li><span><a href=\"#Общий-вывод\" data-toc-modified-id=\"Общий-вывод-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Общий вывод</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и изучение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общая информация о файле"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим все необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\koten\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\koten\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\koten\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\koten\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\koten\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\koten\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим файл и посмотрим первые 5 строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv') # загрузка данных\n",
    "except:\n",
    "    df = pd.read_csv('C:\\\\Users\\\\koten\\\\Downloads\\\\обратотка текстов\\\\toxic_comments.csv') # загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  toxic\n",
      "0  Explanation\\nWhy the edits made under my usern...      0\n",
      "1  D'aww! He matches this background colour I'm s...      0\n",
      "2  Hey man, I'm really not trying to edit war. It...      0\n",
      "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
      "4  You, sir, are my hero. Any chance you remember...      0\n"
     ]
    }
   ],
   "source": [
    "print(df.head()) # просмотр первых 5 строк"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим информацию о файле."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() # получение информации о файле"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таблице всего два столбца: столбец text содержит текст комментария, а toxic — целевой признак. Тип данных у текста object, а у целевого признака int64. Далее посмотрим сколько у нас комментариев, помеченных как токсичные и сколько обычных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts() # подсчет количества занчений по классам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим сильный дисбалланс классов. Это стоит учесть при обучении моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем приступить с обучению, нужно данные очистить от неинформативных символов и слов, а также привести слова к их начальной форме (провести лемматизацию)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем распоряжении текст на английском языке, поэтому для лемматизации будем использовать WordnetLemmatizer. А для улучшения качества лемматизируемого текста мы воспользуемся POS-тегирование, которое отнесет каждое слово к определенной части речи. Для того, чтобы найти правильный POS-тег для каждого слова, сопоставим его с правильным входным символом, который принимает WordnetLemmatizer, и передадим его в качестве второго аргумента в lemmatize().\n",
    "В nltk для этого есть метод nltk.pos_tag(). Он принимает список слов, а возвращает кортеж с тегом POS. Напишем функцию для POS-тегирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word): # функция для создания POS-тегов \n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы сделаем следующее:\n",
    "Напишем функцию, которая:\n",
    "- приведет текст к нижнему регистру\n",
    "- удалит лишние символы\n",
    "- избавится от лишних пробелов\n",
    "\n",
    "В следующем этапе создадим список для хранения преобразованных данных, загрузим словарь стоп-слов и инициализируем лемматизатор.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью цикла пройдемся по столбцу с исходным текстом:\n",
    "- очистим текст\n",
    "- токенизируем\n",
    "- удалим стоп-слова\n",
    "- лемматизируем с учетом POS-тегов\n",
    "\n",
    "И в заключении создадим столбец с обработанным текстом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\koten\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\koten\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "def clean_text(text):\n",
    "   \n",
    "    text = text.lower()  # приводим текст к нижнему регистру\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)  # удаляем лишние символы    \n",
    "    text = \" \".join(text.split()) # удаляем лишние пробелы\n",
    "    \n",
    "    return text # возвращаем очищенные данные\n",
    " \n",
    "\n",
    "processed_text = [] # создаем список для хранения преобразованных данных\n",
    "\n",
    "stop_words = stopwords.words('english') # загружаем стоп-слова для английского языка\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() # инициализируем лемматайзер\n",
    " \n",
    "\n",
    "for text in df['text']: # для каждого сообщения text из столбца data['text']\n",
    "    # cleaning \n",
    "    text = clean_text(text)  # очистка текста    \n",
    "    text = word_tokenize(text) # токенизирование     \n",
    "    text = [word for word in text if word not in stop_words] # удаление стоп-слов  \n",
    "    text = ' '.join([lemmatizer.lemmatize(w,get_wordnet_pos(w)) for w in text]) # лемматизация\n",
    "     \n",
    "    \n",
    "    processed_text.append(text) # добавляем преобразованный текст в список processed_text\n",
    " \n",
    "\n",
    "df['lemm_text'] = processed_text # Сохраняем результат преобразования в новой колонке 'lemm_text'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На примере одного соощения проверим результат нашего преобразования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "Лемматизированный текст: explanation edits make username hardcore metallica fan revert vandalism closure gas vote new york doll fac please remove template talk page since retire\n"
     ]
    }
   ],
   "source": [
    "print(\"Исходный текст:\",df['text'][0])\n",
    "print(\"Лемматизированный текст:\", df['lemm_text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразовани проведены достаточно успешно: весь текст написан в нижнем регистре, между словани один пробел, нет знаков препинания, а также удалены неинформативные для модели слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первом разделе нашего проекта мы посмотрели исходные данные. В нашем распоряжении таблица из двух столбцов: в первом текст комментария, а во втором пометка о том токсичный комментарий или нет. Также мы обнаружили дисбалланс классов, который следует учесть при обучении моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы провели предобработку текста:\n",
    "- очистили текст от ненужных символов\n",
    "- токенизировали\n",
    "- удалили стоп-слова (слова, которые не важны для обучения моделей)\n",
    "- лемматизировали текст с учетом POS-тегов (привели слова к начальной форме)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка признаков к обучению моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборку на признаки и целевой признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df['lemm_text'] # признаки\n",
    "target = df['toxic'] # целевой признак"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую, валидационную и тестовую выборку. Делить будем в соотношении 60/20/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((95742,), (31914,), (31915,), (95742,), (31914,), (31915,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train, features_valid_test, target_train, target_valid_test = train_test_split(features, target, test_size=0.4, random_state=12345)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid_test, target_valid_test, test_size=0.5, random_state=12345)\n",
    "\n",
    "\n",
    "features_train.shape, features_valid.shape, features_test.shape, target_train.shape, target_valid.shape, target_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим сохраняется ли дисбалланс классов при разделении на подвыборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение классов в обучающей выборке:\n",
      "0.8981324810428025\n",
      "0.10186751895719746\n",
      "\n",
      "Распределение классов в обучающей выборке:\n",
      "0.8977878047251989\n",
      "0.10221219527480102\n",
      "\n",
      "Распределение классов в тестовой выборке:\n",
      "0.8994203352655491\n",
      "0.10057966473445089\n"
     ]
    }
   ],
   "source": [
    "print('Распределение классов в обучающей выборке:')\n",
    "print(target_train.value_counts()[0] / target_train.value_counts().sum())\n",
    "print(target_train.value_counts()[1] / target_train.value_counts().sum())\n",
    "print()\n",
    "print('Распределение классов в обучающей выборке:')\n",
    "print(target_valid.value_counts()[0] / target_valid.value_counts().sum())\n",
    "print(target_valid.value_counts()[1] / target_valid.value_counts().sum())\n",
    "print()\n",
    "print('Распределение классов в тестовой выборке:')\n",
    "print(target_test.value_counts()[0] / target_test.value_counts().sum())\n",
    "print(target_test.value_counts()[1] / target_test.value_counts().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим корпуса слов для каждой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = features_train.values.astype('U') #создание корпуса слов на обучающей выборке\n",
    "valid_corpus = features_valid.values.astype('U') #создание корпуса слов на валидационной выборке\n",
    "test_corpus = features_test.values.astype('U') #создание корпуса слов на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь наши данные готовы. Далее мы применем два подхода: \"мешок слов\" и TF-IDT преобразования слов в числа. Для каждого подхода обучим несколько моделей. Учитывая дисбалланс классов при обучении моделей будем использовать 'class_weight'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведём тексты в понятный для машины формат — векторный. Преобразовать слова в векторы поможет модель «мешок слов». Для того чтобы преобразовать корпус текстов в мешок слов, обратимся к классу CountVectorizer(). Применим метод fit(), только к обучающей выборке, иначе тестирование будет нечестным: в модели будут учтены частоты слов из тестовой и валидационной выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(dtype=np.float32) #создаем счетчик\n",
    "bow_train = count_vect.fit_transform(train_corpus) #счетчик выделяет из корпуса уникальные слова и подсчитывает количество их вхождений в каждом тексте корпуса\n",
    "bow_valid = count_vect.transform(valid_corpus)\n",
    "bow_test = count_vect.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее обучим модели линейной регрессии, CatBoostClassifier, LGBMClassifier, SGDRClassifier и XGBClassifier. Метрикой качества будет F1-мера.                                         '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Линейная регрессия\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия\n",
      "F1: 0.744\n",
      "Wall time: 6.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr_bow = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced')\n",
    "model_lr_bow.fit(bow_train, target_train)\n",
    "\n",
    "predicted_valid = model_lr_bow.predict(bow_valid)\n",
    "f1_lr_bow = f1_score(target_valid, predicted_valid) \n",
    "print('Логистическая регрессия')\n",
    "print('F1: {:.3f}'.format(f1_lr_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-мера равна 0.744, а время обучения в пределах 10 секунд, что достаточно быстро, но метрика качества немного не дотягивает до порога в 0.75. Посмотрим как поведут сябя другие модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.072254\n",
      "0:\tlearn: 0.6556605\ttotal: 557ms\tremaining: 9m 16s\n",
      "50:\tlearn: 0.4268949\ttotal: 21s\tremaining: 6m 30s\n",
      "100:\tlearn: 0.3826242\ttotal: 39.8s\tremaining: 5m 54s\n",
      "150:\tlearn: 0.3579584\ttotal: 58.6s\tremaining: 5m 29s\n",
      "200:\tlearn: 0.3310534\ttotal: 1m 17s\tremaining: 5m 7s\n",
      "250:\tlearn: 0.3119354\ttotal: 1m 36s\tremaining: 4m 47s\n",
      "300:\tlearn: 0.2967121\ttotal: 1m 54s\tremaining: 4m 26s\n",
      "350:\tlearn: 0.2846078\ttotal: 2m 13s\tremaining: 4m 7s\n",
      "400:\tlearn: 0.2744319\ttotal: 2m 32s\tremaining: 3m 47s\n",
      "450:\tlearn: 0.2661813\ttotal: 2m 50s\tremaining: 3m 27s\n",
      "500:\tlearn: 0.2589913\ttotal: 3m 9s\tremaining: 3m 8s\n",
      "550:\tlearn: 0.2522776\ttotal: 3m 27s\tremaining: 2m 49s\n",
      "600:\tlearn: 0.2463989\ttotal: 3m 46s\tremaining: 2m 30s\n",
      "650:\tlearn: 0.2406820\ttotal: 4m 4s\tremaining: 2m 11s\n",
      "700:\tlearn: 0.2360708\ttotal: 4m 23s\tremaining: 1m 52s\n",
      "750:\tlearn: 0.2314416\ttotal: 4m 41s\tremaining: 1m 33s\n",
      "800:\tlearn: 0.2273370\ttotal: 5m\tremaining: 1m 14s\n",
      "850:\tlearn: 0.2228581\ttotal: 5m 20s\tremaining: 56s\n",
      "900:\tlearn: 0.2192723\ttotal: 5m 39s\tremaining: 37.3s\n",
      "950:\tlearn: 0.2157137\ttotal: 5m 57s\tremaining: 18.4s\n",
      "999:\tlearn: 0.2123747\ttotal: 6m 15s\tremaining: 0us\n",
      "CatBoost:\n",
      "F1: 0.753\n",
      "Wall time: 6min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_cat_bow = CatBoostClassifier(random_state=12345, auto_class_weights = 'Balanced', custom_metric='F1')\n",
    "model_cat_bow.fit(bow_train, target_train, verbose=50)\n",
    "\n",
    "predicted_valid = model_cat_bow.predict(bow_valid)\n",
    "f1_cat_bow = f1_score(target_valid, predicted_valid)\n",
    "print('CatBoost:')\n",
    "print('F1: {:.3f}'.format(f1_cat_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь F1 уже 0,753, а время обучения увеличилось до 6 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier:\n",
      "F1: 0.740\n",
      "Wall time: 4.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "       \n",
    "model_lgbm_bow = LGBMClassifier(random_state=12345, class_weight='balanced')           \n",
    "model_lgbm_bow.fit(bow_train, target_train)\n",
    "\n",
    "predicted_valid = model_lgbm_bow.predict(bow_valid)\n",
    "\n",
    "f1_lgbm_bow = f1_score(target_valid, predicted_valid)\n",
    "print('LGBMClassifier:')\n",
    "print('F1: {:.3f}'.format(f1_lgbm_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время обучения немного меньше, чем у CatBoost, но и F1 всего 0.74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier:\n",
      "F1: 0.751\n",
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_sdg_bow = SGDClassifier(random_state=12345, class_weight='balanced')\n",
    "model_sdg_bow.fit(bow_train, target_train)\n",
    "\n",
    "predicted_valid = model_sdg_bow.predict(bow_valid)\n",
    "f1_sdg_bow = f1_score(target_valid, predicted_valid)\n",
    "print('LGBMClassifier:')\n",
    "print('F1: {:.3f}'.format(f1_sdg_bow))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошее сочетание срорости обучения (около минуты) и размера F1 - 0.751"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier:\n",
      "F1: 0.734\n",
      "Wall time: 4.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_xgb_bow = XGBClassifier(random_state=12345, scale_pos_weight = 10)\n",
    "model_xgb_bow.fit(bow_train, target_train)\n",
    "          \n",
    "predicted_valid = model_xgb_bow.predict(bow_valid)\n",
    "f1_xgb_bow = f1_score(target_valid, predicted_valid)\n",
    "print('XGBClassifier:')\n",
    "print('F1: {:.3f}'.format(f1_xgb_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хуже всего справилась с задачей модель XGB: F1 всего 0.734, при этом на обучение ушло почти пять минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее посмотрим другой подход к преобразованию текстов в вектора. Мешок слов учитывает частоту употребления слов, а мы посчитаем, как часто уникальное слово встречается во всём корпусе и в отдельном его тексте и определим \"важность\" слова. Оценка важности слова определяется величиной TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучать мы будем те же модели, что и с \"мешком слов\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer() # создаем счетчик\n",
    "\n",
    "tf_idf_train = count_tf_idf.fit_transform(train_corpus)  # расчет TF-IDF для корпуса текстов\n",
    "tf_idf_valid = count_tf_idf.transform(valid_corpus)\n",
    "tf_idf_test = count_tf_idf.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия\n",
      "F1: 0.753\n",
      "Wall time: 953 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr_tf_idf = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced')\n",
    "model_lr_tf_idf.fit(tf_idf_train, target_train)\n",
    "\n",
    "predicted_valid = model_lr_tf_idf.predict(tf_idf_valid)\n",
    "\n",
    "f1_lr_tf_idf = f1_score(target_valid, predicted_valid) \n",
    "print('Логистическая регрессия')\n",
    "print('F1: {:.3f}'.format(f1_lr_tf_idf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 равна 0,753 на валидационной выборке. Время обучения очень маленькое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.072254\n",
      "0:\tlearn: 0.6554324\ttotal: 1.06s\tremaining: 17m 37s\n",
      "50:\tlearn: 0.4252444\ttotal: 34.1s\tremaining: 10m 34s\n",
      "100:\tlearn: 0.3778538\ttotal: 1m 6s\tremaining: 9m 48s\n",
      "150:\tlearn: 0.3491063\ttotal: 1m 38s\tremaining: 9m 11s\n",
      "200:\tlearn: 0.3236512\ttotal: 2m 9s\tremaining: 8m 36s\n",
      "250:\tlearn: 0.3029473\ttotal: 2m 41s\tremaining: 8m 2s\n",
      "300:\tlearn: 0.2874020\ttotal: 3m 13s\tremaining: 7m 28s\n",
      "350:\tlearn: 0.2745307\ttotal: 3m 44s\tremaining: 6m 55s\n",
      "400:\tlearn: 0.2628368\ttotal: 4m 16s\tremaining: 6m 22s\n",
      "450:\tlearn: 0.2531798\ttotal: 4m 47s\tremaining: 5m 50s\n",
      "500:\tlearn: 0.2447450\ttotal: 5m 19s\tremaining: 5m 17s\n",
      "550:\tlearn: 0.2369723\ttotal: 5m 50s\tremaining: 4m 45s\n",
      "600:\tlearn: 0.2299987\ttotal: 6m 21s\tremaining: 4m 13s\n",
      "650:\tlearn: 0.2235184\ttotal: 6m 53s\tremaining: 3m 41s\n",
      "700:\tlearn: 0.2178135\ttotal: 7m 24s\tremaining: 3m 9s\n",
      "750:\tlearn: 0.2121319\ttotal: 7m 56s\tremaining: 2m 37s\n",
      "800:\tlearn: 0.2071866\ttotal: 8m 27s\tremaining: 2m 6s\n",
      "850:\tlearn: 0.2027119\ttotal: 8m 58s\tremaining: 1m 34s\n",
      "900:\tlearn: 0.1979534\ttotal: 9m 30s\tremaining: 1m 2s\n",
      "950:\tlearn: 0.1936157\ttotal: 10m 1s\tremaining: 31s\n",
      "999:\tlearn: 0.1896566\ttotal: 10m 31s\tremaining: 0us\n",
      "CatBoost:\n",
      "F1: 0.760\n",
      "Wall time: 10min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_cat_tf_idf = CatBoostClassifier(random_state=12345, auto_class_weights = 'Balanced', )\n",
    "model_cat_tf_idf.fit(tf_idf_train, target_train, verbose=50)\n",
    "\n",
    "predicted_valid = model_cat_tf_idf.predict(tf_idf_valid)\n",
    "                     \n",
    "f1_cat_tf_idf = f1_score(target_valid, predicted_valid)\n",
    "print('CatBoost:')\n",
    "print('F1: {:.3f}'.format(f1_cat_tf_idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 равна 0.76, пока что это лучший показатель, но время обучения почти 11 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier:\n",
      "F1: 0.738\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "      \n",
    "model_lgbm_tf_idf = LGBMClassifier(random_state=12345, class_weight='balanced')           \n",
    "model_lgbm_tf_idf.fit(tf_idf_train, target_train)\n",
    "\n",
    "predicted_valid = model_lgbm_tf_idf.predict(tf_idf_valid)\n",
    "\n",
    "f1_lgbm_tf_idf = f1_score(target_valid, predicted_valid)\n",
    "print('LGBMClassifier:')\n",
    "print('F1: {:.3f}'.format(f1_lgbm_tf_idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBMClassifier в этом случае, плохо справился с поставленной задачей. При очень быстром обучении (около 20 секунд), F1 всего 0.738"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier:\n",
      "F1: 0.740\n",
      "Wall time: 403 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_sdg_tf_idf = SGDClassifier(random_state=12345, class_weight='balanced')\n",
    "model_sdg_tf_idf.fit(tf_idf_train, target_train)\n",
    "\n",
    "predicted_valid = model_sdg_tf_idf.predict(tf_idf_valid)\n",
    "\n",
    "f1_sdg_tf_idf = f1_score(target_valid, predicted_valid)\n",
    "print('LGBMClassifier:')\n",
    "print('F1: {:.3f}'.format(f1_sdg_tf_idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 равна 0.740, что ниже установленного минимального показателя качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier:\n",
      "F1: 0.723\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "model_xgb_tf_idf = XGBClassifier(random_state=12345, scale_pos_weight = 10)\n",
    "model_xgb_tf_idf.fit(tf_idf_train, target_train)\n",
    "          \n",
    "predicted_valid = model_xgb_tf_idf.predict(tf_idf_valid)\n",
    "f1_xgb_tf_idf = f1_score(target_valid, predicted_valid)\n",
    "print('XGBClassifier:')\n",
    "print('F1: {:.3f}'.format(f1_xgb_tf_idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И опять модель XGB показала худший результат: F1 всего 0,723"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сведем результаты в одну таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты F1  моделей\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 мешок слов</th>\n",
       "      <th>F1 TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Линейная регрессия</th>\n",
       "      <td>0.744</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.753</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.740</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRClassifier</th>\n",
       "      <td>0.751</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.734</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    F1 мешок слов  F1 TF-IDF\n",
       "Линейная регрессия          0.744      0.753\n",
       "CatBoostClassifier          0.753      0.760\n",
       "LGBMClassifier              0.740      0.738\n",
       "SGDRClassifier              0.751      0.740\n",
       "XGBClassifier               0.734      0.723"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_data = {'F1 мешок слов': [f1_lr_bow, f1_cat_bow, f1_lgbm_bow, f1_sdg_bow, f1_xgb_bow ],\n",
    "                       'F1 TF-IDF': [f1_lr_tf_idf, f1_cat_tf_idf, f1_lgbm_tf_idf, f1_sdg_tf_idf, f1_xgb_tf_idf]}\n",
    "score_df = pd.DataFrame(score_data, index = ['Линейная регрессия',\n",
    "                                            'CatBoostClassifier',\n",
    "                                             'LGBMClassifier',\n",
    "                                            'SGDRClassifier','XGBClassifier'])\n",
    "score_df['F1 мешок слов'] = round(score_df['F1 мешок слов'],3)\n",
    "score_df['F1 TF-IDF'] = round(score_df['F1 TF-IDF'],3)\n",
    "print('Результаты F1  моделей')\n",
    "display(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При векторизации текста с помощью \"мешка слов\" лучший результат на валидационной выборке показала модель CatBoostClassifier (F1 = 0.753), на втором месте SGDRClassifier (F1 = 0,751). При применении TF-IDF лучший результат на валидационной выборке опять у CatBoostClassifier (F1 = 0,76), а на втором месте линейная регрессия (F1 = 0.753)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе мы посмотрели два варианта преобразования текства в вектор: \"мешок слов\" и TF-IDF. На преобразованных признаках обучили модели линейной регрессии, CatBoostClassifier, LGBMClassifier, SGDRClassifier и XGBClassifier. Проверили качество на валидационной выборке. В этом проекте метрикой качества является F1-мера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат в обоих случаях показала модель CatBoostClassifier, а худший XGBClassifier. Далее проверим качество моделей на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка моделей на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестированиние моделей построенных с помощью \"мешка слов\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия\n",
      "F1: 0.740\n"
     ]
    }
   ],
   "source": [
    "predicted_test = model_lr_bow.predict(bow_test) # линейная регрессия (\"мешок слов\")\n",
    "f1_lr_bow_test = f1_score(target_test, predicted_test) \n",
    "print('Логистическая регрессия')\n",
    "print('F1: {:.3f}'.format(f1_lr_bow_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostClassifier:\n",
      "F1: 0.747\n"
     ]
    }
   ],
   "source": [
    "predicted_test = model_cat_bow.predict(bow_test) # CatBoostClassifier (\"мешок слов\")\n",
    "f1_cat_bow_test = f1_score(target_test, predicted_test)\n",
    "print('CatBoostClassifier:')\n",
    "print('F1: {:.3f}'.format(f1_cat_bow_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier:\n",
      "F1: 0.738\n"
     ]
    }
   ],
   "source": [
    "predicted_test = model_lgbm_bow.predict(bow_test) # LGBMClassifier (\"мешок слов\")\n",
    "\n",
    "f1_lgbm_bow_test = f1_score(target_test, predicted_test)\n",
    "print('LGBMClassifier:')\n",
    "print('F1: {:.3f}'.format(f1_lgbm_bow_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRClassifier:\n",
      "F1: 0.751\n"
     ]
    }
   ],
   "source": [
    "predicted_test = model_sdg_bow.predict(bow_test) # SGDRClassifier (\"мешок слов\")\n",
    "f1_sdg_bow_test = f1_score(target_test, predicted_test)\n",
    "print('SGDRClassifier:')\n",
    "print('F1: {:.3f}'.format(f1_sdg_bow_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier:\n",
      "F1: 0.733\n"
     ]
    }
   ],
   "source": [
    "predicted_test = model_xgb_bow.predict(bow_test) # XGBClassifier (\"мешок слов\")\n",
    "f1_xgb_bow_test = f1_score(target_test, predicted_test)\n",
    "print('XGBClassifier:')\n",
    "print('F1: {:.3f}'.format(f1_xgb_bow_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование моделей созданных с помощью TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия\n",
      "F1: 0.752\n"
     ]
    }
   ],
   "source": [
    "predicted_test = model_lr_tf_idf.predict(tf_idf_test) # линейная регрессия (\"TF-IDF\")\n",
    "\n",
    "f1_lr_tf_idf_test = f1_score(target_test, predicted_test) \n",
    "print('Логистическая регрессия')\n",
    "print('F1: {:.3f}'.format(f1_lr_tf_idf_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost:\n",
      "F1: 0.757\n"
     ]
    }
   ],
   "source": [
    "predicted_test = model_cat_tf_idf.predict(tf_idf_test) # CatBoost (\"TF-IDF\")\n",
    "                     \n",
    "f1_cat_tf_idf_test = f1_score(target_test, predicted_test)\n",
    "print('CatBoost:')\n",
    "print('F1: {:.3f}'.format(f1_cat_tf_idf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier:\n",
      "F1: 0.735\n"
     ]
    }
   ],
   "source": [
    "predicted_test = model_lgbm_tf_idf.predict(tf_idf_test) # LGBMClassifier (\"TF-IDF\")\n",
    "\n",
    "f1_lgbm_tf_idf_test = f1_score(target_test, predicted_test)\n",
    "print('LGBMClassifier:')\n",
    "print('F1: {:.3f}'.format(f1_lgbm_tf_idf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRClassifier:\n",
      "F1: 0.736\n"
     ]
    }
   ],
   "source": [
    "predicted_test = model_sdg_tf_idf.predict(tf_idf_test) # SGDRClassifier (\"TF-IDF\")\n",
    "\n",
    "f1_sdg_tf_idf_test = f1_score(target_test, predicted_test)\n",
    "print('SGDRClassifier:')\n",
    "print('F1: {:.3f}'.format(f1_sdg_tf_idf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier:\n",
      "F1: 0.728\n"
     ]
    }
   ],
   "source": [
    "predicted_test = model_xgb_tf_idf.predict(tf_idf_test) # XGBClassifier (\"TF-IDF\")\n",
    "f1_xgb_tf_idf_test = f1_score(target_test, predicted_test)\n",
    "print('XGBClassifier:')\n",
    "print('F1: {:.3f}'.format(f1_xgb_tf_idf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сведем полученные данные в одну таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты F1  моделей\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 мешок слов</th>\n",
       "      <th>F1 мешок слов test</th>\n",
       "      <th>F1 TF-IDF</th>\n",
       "      <th>F1 TF-IDF test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Линейная регрессия</th>\n",
       "      <td>0.744</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.753</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.740</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRClassifier</th>\n",
       "      <td>0.751</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.734</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    F1 мешок слов  F1 мешок слов test  F1 TF-IDF  \\\n",
       "Линейная регрессия          0.744               0.740      0.753   \n",
       "CatBoostClassifier          0.753               0.747      0.760   \n",
       "LGBMClassifier              0.740               0.738      0.738   \n",
       "SGDRClassifier              0.751               0.751      0.740   \n",
       "XGBClassifier               0.734               0.733      0.723   \n",
       "\n",
       "                    F1 TF-IDF test  \n",
       "Линейная регрессия           0.752  \n",
       "CatBoostClassifier           0.757  \n",
       "LGBMClassifier               0.735  \n",
       "SGDRClassifier               0.736  \n",
       "XGBClassifier                0.728  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_data = {'F1 мешок слов': [f1_lr_bow, f1_cat_bow, f1_lgbm_bow, f1_sdg_bow, f1_xgb_bow ],\n",
    "              'F1 мешок слов test': [f1_lr_bow_test, f1_cat_bow_test, f1_lgbm_bow_test, f1_sdg_bow_test, f1_xgb_bow_test],\n",
    "             'F1 TF-IDF': [f1_lr_tf_idf, f1_cat_tf_idf, f1_lgbm_tf_idf, f1_sdg_tf_idf, f1_xgb_tf_idf],\n",
    "             'F1 TF-IDF test': [f1_lr_tf_idf_test, f1_cat_tf_idf_test, f1_lgbm_tf_idf_test, f1_sdg_tf_idf_test, f1_xgb_tf_idf_test]\n",
    "             }\n",
    "score_df = pd.DataFrame(score_data, index = ['Линейная регрессия',\n",
    "                                            'CatBoostClassifier',\n",
    "                                             'LGBMClassifier',\n",
    "                                            'SGDRClassifier','XGBClassifier'])\n",
    "score_df['F1 мешок слов'] = round(score_df['F1 мешок слов'],3)\n",
    "score_df['F1 мешок слов test'] = round(score_df['F1 мешок слов test'],3)\n",
    "score_df['F1 TF-IDF'] = round(score_df['F1 TF-IDF'],3)\n",
    "score_df['F1 TF-IDF test'] = round(score_df['F1 TF-IDF test'],3)\n",
    "print('Результаты F1  моделей')\n",
    "display(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В сводной таблице видно, что лучший показатель F1 на тестовой выборке при применении \"мешка слов\" показывает модель SGDRClassifier (F1 0.751). А вот CatBoostClassifier, который на валидационной выборке показывал лучший результат, немного не дотянул до 0.75 (F1 = 0.747). \n",
    "\n",
    "Лучший показатель F1 на тестовой выборке при применении TF-IDF показывает модель CatBoostClassifier (F1 =0,757), на втором месте линейная регрессия (F1=0,752)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном проекте мы обучали модели, которые могли бы искать токсичные комментрии. в нашем распоряжении тексты с комментариями и пометкой, относится ли конкретный текст комментрия к токсичному или нет. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первом разделе мы посмотрели общую информацию о файле. Мы обнаружили дисбалланс классов, который учли при обучении моделей. Также сразу столо понятно, что на исходном тексте модель не сможет учиться. Поэтому мы провели предобработку, создав дополнительный столбец, в который поместили текст очищенный от стоп-слов и знаков препинания. Слова привели к начальной форме и  сделали, так чтобы между словами был только один пробел. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во втором разделе проекта мы очищенный и лемматизированнй текст перевели в векторы, поскольку модели не понимают слова, им нужны числа. Здесь мы применили два подхода: \"мешок слов\" и TF-IDF. Для каждого метода обучили модели линейной регрессии, CatBoostClassifier, LGBMClassifier, SGDRClassifier и XGBClassifier. Проверили качество на валидационной выборке. В этом проекте метрикой качества является F1-мера. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат получился следующий: при векторизации текста с помощью \"мешка слов\" лучший результат на валидационной выборке показала модель CatBoostClassifier (F1 = 0.753), на втором месте SGDRClassifier (F1 = 0,751). При применении TF-IDF лучший результат на валидационной выборке опять у CatBoostClassifier (F1 = 0,76), а на втором месте линейная регрессия (F1 = 0.753). В обоих случаях, худший результат показала модель XGBClassifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В третьем разделе мы проверили качество моделей на тестовой выборке. Результат получили такой: лучший показатель F1 на тестовой выборке при применении \"мешка слов\" показывает модель SGDRClassifier (F1 0.751). \n",
    "Лучший показатель F1 на тестовой выборке при применении TF-IDF показывает модель CatBoostClassifier (F1 =0,757), на втором месте линейная регрессия (F1=0,752).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 3,
    "start_time": "2022-06-17T18:54:06.477Z"
   },
   {
    "duration": 1398,
    "start_time": "2022-06-17T18:54:06.482Z"
   },
   {
    "duration": 2353,
    "start_time": "2022-06-17T18:54:07.882Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-17T18:54:10.237Z"
   },
   {
    "duration": 28,
    "start_time": "2022-06-17T18:54:10.245Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-17T18:54:10.275Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-17T18:54:10.286Z"
   },
   {
    "duration": 154,
    "start_time": "2022-06-17T18:54:10.291Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-17T18:54:10.447Z"
   },
   {
    "duration": 2194,
    "start_time": "2022-06-17T18:55:30.232Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-17T18:55:32.428Z"
   },
   {
    "duration": 785,
    "start_time": "2022-06-17T18:55:32.435Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-17T18:55:33.222Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-17T18:55:33.229Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-17T18:55:33.272Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-17T18:55:33.280Z"
   },
   {
    "duration": 62,
    "start_time": "2022-06-17T18:55:33.285Z"
   },
   {
    "duration": 304,
    "start_time": "2022-06-17T18:55:33.348Z"
   },
   {
    "duration": 2032,
    "start_time": "2022-06-17T18:56:39.979Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-17T18:56:42.013Z"
   },
   {
    "duration": 811,
    "start_time": "2022-06-17T18:56:42.021Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-17T18:56:42.834Z"
   },
   {
    "duration": 42,
    "start_time": "2022-06-17T18:56:42.840Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-17T18:56:42.883Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-17T18:56:42.896Z"
   },
   {
    "duration": 868,
    "start_time": "2022-06-17T18:56:42.901Z"
   },
   {
    "duration": 325,
    "start_time": "2022-06-17T18:56:43.771Z"
   },
   {
    "duration": 167,
    "start_time": "2022-06-17T18:57:13.294Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-17T18:58:08.443Z"
   },
   {
    "duration": 1997,
    "start_time": "2022-06-17T18:58:19.181Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-17T18:58:21.181Z"
   },
   {
    "duration": 773,
    "start_time": "2022-06-17T18:58:21.189Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-17T18:58:21.964Z"
   },
   {
    "duration": 32,
    "start_time": "2022-06-17T18:58:21.971Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-17T18:58:22.004Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-17T18:58:22.011Z"
   },
   {
    "duration": 699786,
    "start_time": "2022-06-17T18:58:22.016Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-17T19:10:01.804Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-17T19:16:43.384Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-17T19:16:48.799Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-17T19:16:53.696Z"
   },
   {
    "duration": 1859,
    "start_time": "2022-06-17T19:17:57.727Z"
   },
   {
    "duration": 1971,
    "start_time": "2022-06-17T19:41:40.376Z"
   },
   {
    "duration": 1355,
    "start_time": "2022-06-17T19:41:42.350Z"
   },
   {
    "duration": 885,
    "start_time": "2022-06-17T19:41:43.706Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-17T19:41:44.594Z"
   },
   {
    "duration": 33,
    "start_time": "2022-06-17T19:41:44.603Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-17T19:41:44.637Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-17T19:41:44.668Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
