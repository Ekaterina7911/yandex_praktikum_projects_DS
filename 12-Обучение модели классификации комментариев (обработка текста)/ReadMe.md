# 12. Обучение модели классификации комментариев (обработка текста)

### Сфера деятельности

Интернет-сервисы, Стартапы

### Цели проекта

Обучить модель классифицировать комментарии по эмоциональному окрасу (позитивные, негативные). В распоряжении набор данных с разметкой о токсичности сообщений

### Описание проекта

1. Предобработка Данных
- Лемматизация с помощью WordNetLemmatizer библиотеки nltk с учетом POS-тегов (приведение слов к начальной форме)
- Удаление лишних символов
- Удаление стоп-слов (список взят из библиотеки nltk)
- Векторизация корпуса с помощью CountVectorizer
- Векторизация корпуса с помощью TfidfVectorizer
2. На преобразованных признаках обучили модели линейной регрессии, CatBoostClassifier, LGBMClassifier, SGDRClassifier и XGBClassifier
3. Проверили качество моделей на тестовой выборке. Посчитали величину F1


### Итоги

Лучший показатель F1 на тестовой выборке при применении "мешка слов" показывает модель SGDRClassifier (F1 0.751). Лучший показатель F1 на тестовой выборке при применении TF-IDF показывает модель CatBoostClassifier (F1 =0,757), на втором месте линейная регрессия (F1=0,752).


### Навыки и инструменты

- предобработка данных
- Python
- Pandas
- NumPy
- Scikit-learn
- CatBoost
- LGBM
- XGB
- nltk
- tf-idf
- лемматизация